# 6.1 Introdução

### Revisão do conteúdo

Introdução sobre XXXXXXX a e detalhes da instalação do cluster Spark XXXXX

{% hint style="info" %}
&#x20;Mais informações estão disponibilizadas na [documentação oficial](https://spark.apache.org/docs/latest/).
{% endhint %}

### Exercício - Instalação

Nesse módulo foram revisados todas as etapas de configuração apresentadas anteriormente, na aula [1.2 Hadoop](../1-big-data-foundations/1.2-hadoop.md).

**1. Instalação do docker e docker-compose**&#x20;

* Já realizado no módulo anterior ([1.2 Hadoop](../1-big-data-foundations/1.2-hadoop.md))

**2. Executar os seguintes comandos, para baixar as imagens do Cluster de Big Data:**

`git clone https://github.com/rodrigo-reboucas/docker-bigdata.git spark`\
`cd spark`\
`docker-compose –f docker-compose-parcial.yml pull`

Nessa etapa recebi as seguintes mensagens de erro:

```bash
ERROR: for mongo Cannot create container for service mongo: Conflict. The container name "/mongo" is already in use by container "e65b7a8ac1e0c221f0e578f747fb57b2b43b1fc8f3b0157d2c73c734c7bf60bb". You have to remove (or rename) that container to be able to reuse that name.
ERROR: for zookeeper Cannot create container for service zookeeper: Conflict. The container name "/zookeeper" is already in use by container "728279aba2d5c27ea885962c2c6cf92e35c0b1428be5cdcb6fdb02eb609fe381". You have to remove (or rename) that container to be able to reuse that name. ERROR: Encountered errors while bringing up the project.
```

Para solucionar, fiz o docker-compose down dos serviços utilizados anteriormente: docker-bigdata | elastic | kafka | mongodb | redis.

Ao reexecutar o comando, o update foi realizado com sucesso.

**3. Iniciar o cluster Hadoop através do docker-compose**`docker-compose –f docker-compose-parcial.yml up -d`

![](<../.gitbook/assets/m6\_aula1\_01 (1).png>)

**4. Listas as imagens em execução**

* Para listar os containers, utilizar o comando `docker ps,` no qual é possível verificar todos os containers que estão sendo executados e algumas de suas propriedades.

![](../.gitbook/assets/m6\_aula1\_02.png)

**5. Verificar os logs dos containers do docker-compose em execução**

* Para verificar logs, utilizar o comando `docker-compose logs,` no qual é detalhado todos os logs do cluster (database, hive, namenode, spark, zookeeper, ...) &#x20;

![](../.gitbook/assets/m6\_aula1\_03.png)

**6. Verificar os logs do container jupyter-spark**

* Para essa etapa, utilizar o comando `docker logs jupyter-spark`&#x20;

![](../.gitbook/assets/m6\_aula1\_04.png)

**7. Acessar pelo browser o Jupyter, através do link:**

* [http://localhost:8889](http://localhost:8889)

![](../.gitbook/assets/m6\_aula1\_05.png)
